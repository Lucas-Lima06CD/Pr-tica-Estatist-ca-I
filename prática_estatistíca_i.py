# -*- coding: utf-8 -*-
"""Prática Estatistíca I

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KCPkw1UqmZMkTTuE4KDPYiZjF3DemFHK

# **Importando as bibliotecas**
"""

import pandas as pd # Para leitura de Arquivos CSVs
import numpy as np # Geração de números aleatórios

"""# **Importando Base de dados**

"""

from google.colab import files
uploaded = files.upload()

file_name = next(iter(uploaded))
Base = pd.read_csv(file_name)

Base

"""# **Amostragem de dados Simples**

"""

# Verificando o tamaho da base
Base.shape

# Gerando semente aleatória para os resultados em várias execuções
np.random.seed(2345)

# 150 amostras, intervalo de 0 a 1, com reposição, probabilidades equivalentes
amostra = np.random.choice(a = [0,1], size = 150, replace = True, p = [0.7, 0.3])

amostra

len(amostra[amostra==1])
len(amostra[amostra==0])

Base_final = Base.loc[amostra==0]

Base_final.shape

"""# **Amostragem de dados Sistemática**"""

import pandas as pd
import numpy as np
from math import ceil #Pega o maior valor de uma divisão de números reais

# Criando variáveis para representar uma população, amostra e valor de K
população = 150
amostra = 15
K = ceil(população / amostra)

K
# Para se obter um valor aleatório, deve-se extrair 5 a cada 60

# Definindo um valor randomico para iniciar a amostra, inicio de 1 até k+1
r = np.random.randint(low = 1, high= K + 1, size = 1)

r

# Criando um for para a soma dos próximos valores, com o valor r determinado no script acima
# K = 10 e r = 6, logo 10+6 = 16
acumulador = r[0]
sorteados = []
for i in range(amostra):
  sorteados.append(acumulador)
  acumulador += K

sorteados

# Carregando arquivo csv (Iris)
from google.colab import files
uploaded = files.upload()

file_name = next(iter(uploaded))
Base = pd.read_csv(file_name)

# Base_filtrada = filtro da base carregada com o "Sorteados"
Base_filtrada = Base.loc[sorteados]

Base_filtrada

"""# **Amostragem de dados Estratificada**"""

# Carregamento de bibliotecas necessárias
import pandas as pd
from sklearn.model_selection import train_test_split

# Carregamento do arquivo csv pelo google collab
from google.colab import files
uploaded = files.upload()

file_name = next(iter(uploaded))
iris = pd.read_csv(file_name)

iris["class"].value_counts()

# Iris.iloc [:, 0:4] = atributos previsores, dados sobre a pétala e sétala da planta
# Iris.iloc [:, 4] = considerando apenas a classe, a especie das 3 plantas
# Test_size = Coleta de 50% da base usados para para variáveis X e Y, a f(XY) retorna 4 valores

X,_,Y,_ = train_test_split(iris.iloc[:, 0:4], iris.iloc[:, 4], test_size = 0.5, stratify = iris.iloc[:, 4])

Y.value_counts()

"""# **Medidas Centrabilidade e Variabilidade**"""

# importando bibliotecas necessárias
import numpy as np
from scipy import stats

# Criando uma variável de dados
X = [234, 290, 567,376,753,2,871,305,2]

# Média dos do conjuto X
np.mean(X)

# Mediana
np.median(X)

# Moda
moda = stats.mode(X)
moda

# Criando Variável para geração de quartis (0%, 25%, 50% e 100%)
quartis = np.quantile(X, [0, 0.25, 0.50, 1])
quartis

# Devio padrão
np.std(X, ddof=1)

stats.describe(X)

"""# **Distribuição Normal**"""

# Importando função norm
from scipy.stats import norm

# Em um determinado conjunto de dados onde a média é 8 e o desvio padrão é 2. Determine a a probabilidade de tirar um dado <6
norm.cdf(6, 8, 2)

# Probabilidade de obter um dado >6
norm.sf(6, 8, 2)

# Probabilidade de obter um dado <6 ou >10
norm.cdf(6, 8, 2) + norm.sf(10, 8, 2)
# Calculando as probabilidades das duas caudas da distribuição, é a feito a soma das duas probabilidades